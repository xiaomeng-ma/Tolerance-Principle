\section{Discussion}
In language acquisition, rule-based learning is very common, such as past-tense acquisition. But what leads to rule learning in the first place? Yang proposed the Tolerance Principle predict when a rule will be productive. He hypothesizes when the cost to process a word in a list with a rule is minimum a rule will be produced. In order to estimate the cost to process a word, he based his calculations on two assumptions: 1) lexical retrieval is a serial search process; 2) the distribution of children's effective vocabulary is Zipfian. Thus, he uses the TP to quantify a threshold number of exceptions ($\theta$) that a learner can tolerate: $\theta = N/ln(N)$. However, the corpus data doesn't support the threshold predicted by the TP. Yang examined Adam's and Eve's data and neither conform to the TP's threshold. 

This paper revisted his second assumption in the TP calculation and revised the testing methodology to make it more appropriate for the corpus data. We then used the revised methods to test eight children's past-tense acquisition data (including Adam's and Eve's). Five of the  eight children's data support the TP's prediction. We further investigated the other three children's data and explored how sample size affects the testability of the TP. The results showed that the TP requires a relatively densely sampled corpus to be tested true. 

What is a "densely sampled corpus"? Based on our empirical data, $N$ needs to be at least over 120 and the $e$ has to be less than 33\% of $N$. However, we don't have any good explanation. The density of the corpus could affect all four variables in the TP formula, the number of types of items $N$ and exceptions $e$, and the distribution of $N$ and $e$, thus changing the exponent $\alpha$ and $\beta$. The interaction of the four variables and their relationship to the TP worth further investigation.  